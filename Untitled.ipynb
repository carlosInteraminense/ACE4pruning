{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch_pruning as tp\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "\n",
    "from decimal import *\n",
    "\n",
    "from PIL import Image\n",
    "import math\n",
    "import vgg\n",
    "import os\n",
    "import timeit\n",
    "import operator\n",
    "import copy\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "def make_layers(cfg, batch_norm=False):\n",
    "    layers = []\n",
    "    in_channels = 3\n",
    "    for v in cfg:\n",
    "        if v == 'M':\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        else:\n",
    "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
    "            if batch_norm:\n",
    "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "            else:\n",
    "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "            in_channels = v\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "def copy_bias(bias, bias_new):\n",
    "    for i in range(len(bias)):\n",
    "        bias_new[i] = bias[i]\n",
    "\n",
    "cfgs = {\n",
    "    'A': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'B': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'D': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'E': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16 = models.vgg16(pretrained=True)\n",
    "model = vgg.VGG(make_layers(cfgs['D'], batch_norm=False), num_classes=1000, init_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_aux={\n",
    "    'classifier.0.weight':'hl_1.weight',\n",
    "    'classifier.0.bias':'hl_1.bias',\n",
    "    'classifier.3.weight':'hl_2.weight',\n",
    "    'classifier.3.bias':'hl_2.bias',\n",
    "    'classifier.6.weight':'out_layer.weight',\n",
    "    'classifier.6.bias':'out_layer.bias'}\n",
    "\n",
    "state_dict_pre_trained = vgg16.state_dict()\n",
    "state_dict = model.state_dict()\n",
    "for key in state_dict_pre_trained:\n",
    "    #print (key)\n",
    "    w_pre = state_dict_pre_trained[key].data.numpy()\t\n",
    "    if (key in state_dict):\n",
    "        w_new = state_dict[key].data.numpy()\n",
    "    else:\n",
    "        w_new = state_dict[d_aux[key]].data.numpy()\n",
    "\n",
    "    copy_bias(w_pre, w_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_db_dir\t= '/media/carlos/Data/Mestrado/datasets/imagenet/ILSVRC2012_img_drop_aux/'\n",
    "val_db_dir\t = '/media/carlos/Data/Mestrado/datasets/imagenet/ILSVRC2012_img_val_aux/'\n",
    "map_label_file = '/media/carlos/Data/Mestrado/datasets/imagenet/map_index_label.txt'\n",
    "\n",
    "map_index_to_label = {}\n",
    "f = open(map_label_file)\n",
    "f = f.readlines()\n",
    "\n",
    "for i in range(len(f)):\n",
    "    line = f[i]\n",
    "    map_index_to_label[line.split('\\n')[0]] = i\n",
    "\n",
    "X_drop = []\n",
    "y_drop = []\n",
    "X_val = []\n",
    "y_val = []\n",
    "for label in os.listdir(drop_db_dir):\n",
    "    for img in os.listdir(drop_db_dir + '/' + label):\n",
    "        y_drop.append(map_index_to_label[label])\n",
    "        X_drop.append(drop_db_dir + '/' + label + '/' + img)\n",
    "\n",
    "for label in os.listdir(val_db_dir):\n",
    "    for img in os.listdir(val_db_dir + '/' + label):\n",
    "        y_val.append(map_index_to_label[label])\n",
    "        X_val.append(val_db_dir + '/' + label + '/' + img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_act_neuron(x, mode = 'sigmoid', mean = None, std = None, threshold = None):\n",
    "    if (mode == 'sigmoid'):\n",
    "        if ((1.0 / (1 + math.exp(-x))) > 0.5): return 1\n",
    "    elif (mode == 'mean_std'):\n",
    "        if (((x - mean) / std) > threshold): return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_threshold = [2]\n",
    "N_HIDDEN_LAYERS = 2\n",
    "num_neurons_hidden_layer = 4096\n",
    "l_percent_to_drop = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "l_acc = {}\n",
    "l_n_parameters = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pruning_by_new_ace_approach(model, l_ace, percent=0.1, is_by_class=False, percent_classes_max_to_drop=0.05, is_by_both_class=False):\n",
    "    #is_by_class = True\n",
    "    drop_neurons = {}\n",
    "    if (is_by_class):\n",
    "        if (not is_by_both_class):\n",
    "            #l_ace[label][l][i]\n",
    "            max_classes_to_drop = len(l_ace) * percent_classes_max_to_drop\n",
    "            max_classes_to_drop_dict = {}\n",
    "            for label in l_ace:\n",
    "                # print ('label: {}'.format(label))\n",
    "                for n_layer in l_ace[label]:\n",
    "                    if (n_layer not in max_classes_to_drop_dict):\n",
    "                        max_classes_to_drop_dict[n_layer] = {}\n",
    "                    n_neurons_to_drop = int(len(l_ace[label][n_layer]) * percent)\n",
    "                    # print ('n_neurons_to_drop in layer {} = {}'.format(n_layer, n_neurons_to_drop))\n",
    "\n",
    "                    l_aux = []\n",
    "                    for idx_neuron in l_ace[label][n_layer]:\n",
    "                        if (n_neurons_to_drop == 0): break\n",
    "                        l_aux.append(idx_neuron)\n",
    "                        n_neurons_to_drop-=1\n",
    "                    # print (len(l_aux))\n",
    "                    if (n_layer not in drop_neurons):\n",
    "                        drop_neurons[n_layer] = []\n",
    "                        for i in l_aux: drop_neurons[n_layer].append(i)\n",
    "                    else:\n",
    "                        l_to_remove = []\n",
    "                        for n in drop_neurons[n_layer]:\n",
    "\n",
    "                            if (n not in l_aux):\n",
    "                                if (n not in max_classes_to_drop_dict[n_layer]):\n",
    "                                    max_classes_to_drop_dict[n_layer][n] = 1\n",
    "                                    max_classes_to_drop_dict[n_layer][n] += 1\n",
    "                                if (max_classes_to_drop_dict[n_layer][n] >= max_classes_to_drop):\n",
    "                                    l_to_remove.append(n)\n",
    "                        for n in l_to_remove:\n",
    "                            drop_neurons[n_layer].remove(n)\n",
    "        else:\n",
    "            max_classes_to_drop = len(l_ace) * percent_classes_max_to_drop\n",
    "            max_classes_to_drop_dict = {}\n",
    "\n",
    "            for label in l_ace:\n",
    "                for n_layer in l_ace[label]:\n",
    "                    max_classes_to_drop_dict[n_layer] = {}\n",
    "                    drop_neurons[n_layer] = []\n",
    "\n",
    "            for label in l_ace:\n",
    "                l_ace_aux = []\n",
    "                for idx_neuron in l_ace[label][1]:\n",
    "                    l_ace_aux.append((l_ace[label][1][idx_neuron], idx_neuron, 1))\n",
    "                    l_ace_aux.append((l_ace[label][2][idx_neuron], idx_neuron, 2))\n",
    "                l_ace_aux.sort()\n",
    "                n_neurons_to_drop = int(len(l_ace_aux) * percent)\n",
    "                l_aux = []\n",
    "                for i in range(len(l_ace_aux)):\n",
    "                    if (n_neurons_to_drop == 0): break\n",
    "                    drop_neurons[l_ace_aux[i][2]].append(l_ace_aux[i][1])\n",
    "                    l_aux.append(l_ace_aux[i][1])\n",
    "                    n_neurons_to_drop-=1\n",
    "\n",
    "                for n_layer in l_ace[label]:\n",
    "                    l_to_remove = []\n",
    "                    for n in drop_neurons[n_layer]:\t\t\t\t\t\t\n",
    "                        if (n not in l_aux):\n",
    "                            if (n not in max_classes_to_drop_dict[n_layer]):\n",
    "                                max_classes_to_drop_dict[n_layer][n] = 1\n",
    "                            max_classes_to_drop_dict[n_layer][n] += 1\n",
    "                            if (max_classes_to_drop_dict[n_layer][n] >= max_classes_to_drop):\n",
    "                                l_to_remove.append(n)\n",
    "                    for n in l_to_remove:\n",
    "                        drop_neurons[n_layer].remove(n)\n",
    "    else:\n",
    "        if (not is_by_both_class):\n",
    "            for n_layer in l_ace:\n",
    "                drop_neurons[n_layer] = []\n",
    "                n_neurons_to_drop = int(len(l_ace[n_layer]) * percent)\n",
    "                for idx_neuron in l_ace[n_layer]:\n",
    "                    if (n_neurons_to_drop == 0): break\n",
    "                    #print ('{}: {}'.format(idx_neuron, l_ace[n_layer][idx_neuron]))\n",
    "                    drop_neurons[n_layer].append(idx_neuron)\n",
    "                    n_neurons_to_drop-=1\n",
    "\n",
    "        #selecting neurons considering both layers in sort!\n",
    "        else:\n",
    "            l_ace_aux = []\n",
    "            for idx_neuron in l_ace[1]:\n",
    "                l_ace_aux.append((l_ace[1][idx_neuron], idx_neuron, 1))\n",
    "                l_ace_aux.append((l_ace[2][idx_neuron], idx_neuron, 2))\n",
    "            l_ace_aux.sort()\n",
    "\n",
    "            n_neurons_to_drop = int(len(l_ace_aux) * percent)\n",
    "            for n_layer in l_ace:\n",
    "                drop_neurons[n_layer] = []\n",
    "\n",
    "            for i in range(len(l_ace_aux)):\n",
    "                if (n_neurons_to_drop == 0): break\n",
    "                drop_neurons[l_ace_aux[i][2]].append(l_ace_aux[i][1])\n",
    "                n_neurons_to_drop-=1\n",
    "        # END --> selecting neurons considering both layers in sort!\n",
    "\n",
    "    new_pruned_model = copy.deepcopy(model)\n",
    "\n",
    "    # Build dependency graph\n",
    "    DG = tp.DependencyGraph()\n",
    "    DG.build_dependency(new_pruned_model, example_inputs=torch.randn(1,3,224,224))\n",
    "\n",
    "    # get a pruning plan according to the dependency graph. idxs is the indices of pruned filters.\n",
    "    pruning_plan = DG.get_pruning_plan( new_pruned_model.hl_1, tp.prune_linear, idxs=drop_neurons[1] )\n",
    "    pruning_plan.exec()\n",
    "    pruning_plan = DG.get_pruning_plan( new_pruned_model.hl_2, tp.prune_linear, idxs=drop_neurons[2] )\n",
    "    pruning_plan.exec()\n",
    "\n",
    "    return new_pruned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_acc_from_model_(model, X_val, y_val, top_n=1):\n",
    "    l_relu_values = {}\n",
    "    l_acc   = [0.0 for i in range(top_n)]\n",
    "    \n",
    "    acc = 0.0\n",
    "    count = 0\n",
    "    \n",
    "    start = time.time()\n",
    "    for i in range(len(X_val)):\n",
    "        filename = X_val[i]\n",
    "        exp_out = y_val[i]\n",
    "        #exp_out = np.argmax(exp_out)\n",
    "\n",
    "        input_image = Image.open(filename)\n",
    "        #print ('{}: {}'.format(i, filename))\n",
    "        #input_torchvar = autograd.Variable(torch.FloatTensor(inp), requires_grad=True)\n",
    "        try:\n",
    "            input_tensor = preprocess(input_image)\n",
    "        except:\n",
    "            #print(\"An exception occurred\")\n",
    "            continue\n",
    "        count+=1\n",
    "        input_batch = torch.unsqueeze(input_tensor, 0) # create a mini-batch as expected by the model\n",
    "\n",
    "        # move the input and model to GPU for speed if available\n",
    "        if torch.cuda.is_available():\n",
    "            input_batch = input_batch.to(device)\n",
    "            model.to(device)\n",
    "        model.eval()\n",
    "        out_model = model.forward_hidden_test(input_batch, 200)\n",
    "\n",
    "        out_softmax = torch.nn.functional.softmax(out_model[-1], dim=-1)\n",
    "        out_softmax = out_softmax.reshape(1000)\n",
    "        out_aux = {}\n",
    "        i = 0\n",
    "        for key in out_softmax.cpu().detach().numpy():\n",
    "            out_aux[i] = key\n",
    "            i+=1\n",
    "        out_aux = dict( sorted(out_aux.items(), key=operator.itemgetter(1),reverse=True))\n",
    "\n",
    "        count_ = 0\n",
    "        for key in out_aux:\n",
    "            if (count_ >= top_n): break\n",
    "\n",
    "            if (exp_out == key):\n",
    "                for j in range(count_, top_n):\n",
    "                    l_acc[j]+=1\n",
    "                acc += 1\n",
    "                break\n",
    "            count_ +=1\n",
    "    for j in range(top_n):\n",
    "        l_acc[j] /= count\n",
    "    end = time.time()\n",
    "    print('Time do compute accuracy: {}'.format(end-start))\n",
    "    return (acc/count), l_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ace_for_class(p_z, p_x_given_z, comb_z_x_index, p_y_given_x, label):\n",
    "    ace = {1:{}, 2:{}}\n",
    "    prod_p_z_comb = {}\n",
    "    for x_index in range(4096):\n",
    "        ace[1][x_index]=Decimal(0)\n",
    "        ace[2][x_index]=Decimal(0)\n",
    "\n",
    "    for layer in p_z:\n",
    "        for z_index in p_z[layer]:\n",
    "            total = float(sum(p_z[layer][z_index]))\n",
    "            if (total != 0):\n",
    "                p_z[layer][z_index][0] /= total\n",
    "                p_z[layer][z_index][1] /= total\n",
    "\n",
    "        for comb in comb_z_x_index[layer]:\n",
    "            for x_index in comb_z_x_index[layer][comb]:\n",
    "                total = float(sum(comb_z_x_index[layer][comb][x_index]))\n",
    "                if (total != 0):\n",
    "                    comb_z_x_index[layer][comb][x_index][0]/=total\n",
    "                    comb_z_x_index[layer][comb][x_index][1]/=total\n",
    "\n",
    "        for pa_y in p_y_given_x[layer]:\n",
    "            total = float(sum(p_y_given_x[layer][pa_y]))\n",
    "            if (total != 0):\n",
    "                p_y_given_x[layer][pa_y][0]/=total\n",
    "                p_y_given_x[layer][pa_y][1]/=total\n",
    "        #NA TENTATIVA DE COMPUTAR O ACE POR CLASSE!!!!\n",
    "        #for pa_y in p_y_given_x[layer][label]:\n",
    "        #    total = float(sum(p_y_given_x[layer][label][pa_y]))\n",
    "        #    if (total != 0):\n",
    "        #        p_y_given_x[layer][label][pa_y][0]/=total\n",
    "        #        p_y_given_x[layer][label][pa_y][1]/=total\n",
    "\n",
    "        prod_p_z_comb[layer] = {}\n",
    "        for comb_z in comb_z_x_index[layer]: #max 50\n",
    "            p_z_ = Decimal(1)\n",
    "            for z_index in range(len(comb_z)): #25k e 4k\n",
    "                z_value = int(comb_z[z_index])\n",
    "                v = Decimal(p_z[layer][z_index][z_value])\n",
    "                p_z_ *= (v)\n",
    "                if (p_z_ == 0):break\n",
    "            prod_p_z_comb[layer][comb_z] = p_z_\n",
    "        \n",
    "        \n",
    "    print('passou..')    \n",
    "    for layer in p_x_given_z:\n",
    "        print ('layer: {}. len = {}'.format(layer, len(p_x_given_z[layer])))\n",
    "        for x_index in p_x_given_z[layer]: # 4096\n",
    "            begin = timeit.default_timer()\n",
    "            #NA TENTATIVA DE COMPUTAR O ACE POR CLASSE!!!!\n",
    "            #for comb_x in p_y_given_x[layer][label]: #máx 50\n",
    "            #    if (p_y_given_x[layer][label][comb_x][1] == 0): continue\n",
    "            for comb_x in p_y_given_x[layer]: #max 50\n",
    "                if (p_y_given_x[layer][comb_x][1] == 0): continue\n",
    "                #só considera o x que ativado\n",
    "                if (int(comb_x[x_index]) != 1): continue\n",
    "\n",
    "                for comb_z in comb_z_x_index[layer]: #max 50\n",
    "                    p_z_ = prod_p_z_comb[layer][comb_z]\n",
    "                    #for z_index in range(len(comb_z)): #25k e 4k\n",
    "                    #    z_value = int(comb_z[z_index])\n",
    "                    #    v = Decimal(p_z[layer][z_index][z_value])\n",
    "                    #    p_z_ *= (v)\n",
    "                    #    if (p_z_ == 0):break                    \n",
    "                    if (p_z_ == 0): continue\n",
    "\n",
    "                    p_x = Decimal(1)\n",
    "                    for x_i in range(len(comb_x)): #50\n",
    "                        #desconsidera o x que estamos computando o ACE\n",
    "                        if (x_i == x_index): continue\n",
    "\n",
    "                        x_value = int(comb_x[x_i])\n",
    "                        p_x *= Decimal(comb_z_x_index[layer][comb_z][x_i][x_value])\n",
    "                        if (p_x == 0): break\n",
    "                    if (p_x == 0): continue\n",
    "                    #NA TENTATIVA DE COMPUTAR O ACE POR CLASSE!!!!\n",
    "                    #ace[layer][x_index] += p_z_*p_x*Decimal(p_y_given_x[layer][label][comb_x][1])\n",
    "                    ace[layer][x_index] += p_z_*p_x*p_y_given_x[layer][comb_x][1]\n",
    "            end = timeit.default_timer()\n",
    "            print ('{}/{} ({}s) = {}'.format(x_index+1, len(p_x_given_z[layer]), end - begin, ace[layer][x_index]))\n",
    "\n",
    "        #ace[layer] = dict(sorted(ace[layer].items(), key=operator.itemgetter(1),reverse=False))\n",
    "        #NA TENTATIVA DE COMPUTAR O ACE POR CLASSE!!!!\n",
    "        ace[layer] = dict(sorted(ace[layer].items(), key=operator.itemgetter(1),reverse=False))\n",
    "        # for x in ace[layer]:\n",
    "        #     print ('{}: {}'.format(x, ace[layer][x]))\n",
    "        #     input()\n",
    "    return ace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_variables():\n",
    "    p_z = {1:{}, 2:{}}\n",
    "    p_x_given_z = {1:{}, 2:{}}\n",
    "    comb_z_x_index = {1:{}, 2:{}}\n",
    "    p_y_given_x = {1:{}, 2:{}}\n",
    "    #NA TENTATIVA DE COMPUTAR O ACE POR CLASSE!!!!\n",
    "    #for i in range(1000):\n",
    "    #    p_y_given_x[1][i] = {}\n",
    "    #    p_y_given_x[2][i] = {}\n",
    "    for z_index in range(25088):\n",
    "        p_z[1][z_index] = [0, 0]\n",
    "    for z_index in range(4096):\n",
    "        p_z[2][z_index] = [0, 0]\n",
    "        p_x_given_z[1][z_index]={}\n",
    "        p_x_given_z[2][z_index]={}\n",
    "    return p_z, p_x_given_z, comb_z_x_index, p_y_given_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ace(X_drop, y_drop, is_by_both_class):\n",
    "    global prefix_filename\n",
    "    global d_relu_mean \n",
    "    global d_relu_std   \n",
    "    fout = open(prefix_filename + '.csv', 'w')\n",
    "    for threshold in l_threshold:\n",
    "        p_z, p_x_given_z, comb_z_x_index, p_y_given_x = init_variables()\n",
    "        label = y_drop[0]\n",
    "        #l_ace[label] = {}\n",
    "        start_proc_imgs = timeit.default_timer()\n",
    "        for i in range(len(X_drop)):\n",
    "            if (i%1000 == 0):\n",
    "                stop_aux = timeit.default_timer()\n",
    "                print ('processing img #{} ({}s)'.format(i, stop_aux - start_proc_imgs))\n",
    "                start_proc_imgs = timeit.default_timer()\n",
    "            filename = X_drop[i]\n",
    "            exp_out = y_drop[i]\n",
    "            \n",
    "            #NA TENTATIVA DE COMPUTAR O ACE POR CLASSE!!!!\n",
    "            #if (exp_out != label):\n",
    "            #    l_ace[label] = compute_ace_for_class(p_z, p_x_given_z, comb_z_x_index, p_y_given_x, label)\n",
    "            #    p_z, p_x_given_z, comb_z_x_index, p_y_given_x = init_variables()\n",
    "            #    label = exp_out\n",
    "\n",
    "            input_image = Image.open(filename)\n",
    "            input_tensor  = None\n",
    "            try: input_tensor = preprocess(input_image)\n",
    "            except: continue\n",
    "            input_batch = torch.unsqueeze(input_tensor, 0) # create a mini-batch as expected by the model\n",
    "            \n",
    "            # move the input and model to GPU for speed if available\n",
    "            #if torch.cuda.is_available(): \n",
    "            input_batch = input_batch.to(device)\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                out_model = model.forward(input_batch)\n",
    "\n",
    "            out_softmax = torch.nn.functional.softmax(out_model[-1], dim=-1)\n",
    "            out_softmax = out_softmax.reshape(1000)\n",
    "            \n",
    "            out_softmax = np.argmax(out_softmax.cpu().detach().numpy())\n",
    "            \n",
    "            for layer in range(1, N_HIDDEN_LAYERS + 1):\n",
    "                mean = d_relu_mean[layer]\n",
    "                std = d_relu_std[layer]\n",
    "                out = out_model[layer].cpu().detach().numpy()\n",
    "                comb = ''\n",
    "                out_previous_layer = out_model[layer-1].cpu().detach().numpy()\n",
    "                \n",
    "                for z_index in range(len(out_previous_layer[0])):\n",
    "                    is_act_z = is_act_neuron(x = out_previous_layer[0][z_index], mode = 'mean_std', mean=mean, std=std, threshold=threshold)\n",
    "                    p_z[layer][z_index][is_act_z]+=1\n",
    "                    comb += str(is_act_z)\n",
    "                if (comb not in comb_z_x_index[layer]): comb_z_x_index[layer][comb]={}\n",
    "                comb_pa_y = ''\n",
    "                for x_index in range(len(out[0])):\n",
    "                    if (x_index not in comb_z_x_index[layer][comb]): comb_z_x_index[layer][comb][x_index] = [0, 0]\n",
    "                    if (comb not in p_x_given_z[layer][x_index]): p_x_given_z[layer][x_index][comb] = [0, 0]\n",
    "                    \n",
    "                    x_value = out[0][x_index]\n",
    "                    is_act_x = is_act_neuron(x_value)\n",
    "                    comb_pa_y += str(is_act_x)\n",
    "                    p_x_given_z[layer][x_index][comb][is_act_x]+=1\n",
    "                    comb_z_x_index[layer][comb][x_index][is_act_x]+=1\n",
    "                \n",
    "                if (comb_pa_y not in p_y_given_x[layer]):\n",
    "                    p_y_given_x[layer][comb_pa_y] = [0, 0]\n",
    "\n",
    "                if (out_softmax == exp_out):\n",
    "                    p_y_given_x[layer][comb_pa_y][1]+=1\n",
    "                else:\n",
    "                    p_y_given_x[layer][comb_pa_y][0]+=1\n",
    "                #NA TENTATIVA DE COMPUTAR O ACE POR CLASSE!!!!\n",
    "                #if (comb_pa_y not in p_y_given_x[layer][out_softmax]):\n",
    "                #     p_y_given_x[layer][out_softmax][comb_pa_y] = [0, 0]\n",
    "                #\n",
    "                #if (out_softmax == exp_out):\n",
    "                #     p_y_given_x[layer][out_softmax][comb_pa_y][1]+=1\n",
    "                #else:\n",
    "                #     p_y_given_x[layer][out_softmax][comb_pa_y][0]+=1\n",
    "        #NA TENTATIVA DE COMPUTAR O ACE POR CLASSE!!!!\n",
    "        #l_ace[label] = compute_ace_for_class(p_z, p_x_given_z, comb_z_x_index, p_y_given_x, label)\n",
    "        l_ace = compute_ace_for_class(p_z, p_x_given_z, comb_z_x_index, p_y_given_x, label)\n",
    "\n",
    "        fout_ace = open(prefix_filename + 'ace.txt','w')\n",
    "        for layer in l_ace:\n",
    "            fout_ace.write('layer {}\\n'.format(layer))\n",
    "            fout_ace.write('{}\\n'.format(l_ace[layer]))\n",
    "\n",
    "        for percent in l_percent_to_drop:\n",
    "            start_pruning = timeit.default_timer()\n",
    "            print ('percent to pruning for threshold = {}: {}'.format( percent, threshold))\n",
    "            #model_clone = copy.deepcopy(model)\n",
    "            #for percent_classes_max_to_drop in [0, 0.05, 0.1, 0.2, 0.3]:\n",
    "            pruned_model = pruning_by_new_ace_approach(model, l_ace, percent, is_by_class=True, percent_classes_max_to_drop=0.05, is_by_both_class=is_by_both_class)\n",
    "\n",
    "            acc = compute_acc_from_model_(pruned_model, X_val, y_val, top_n=5)\n",
    "            #l_acc[threshold][percent] = acc\n",
    "            n_parameters = count_parameters(pruned_model)\n",
    "            del pruned_model\n",
    "            torch.cuda.empty_cache()\n",
    "            stop_pruning = timeit.default_timer()\n",
    "            print('Time to prunning and compute acc for new model: ', stop_pruning - start_pruning)\n",
    "            for i in range(len(acc[1])):\n",
    "                acc[1][i] = str(acc[1][i]).replace('.', ',')\n",
    "            fout.write('{};{};{};{};{};{};{};{};\\n'.format(threshold, percent ,n_parameters, acc[1][0], acc[1][1], acc[1][2], acc[1][3], acc[1][4]))\n",
    "            print ('{};{};{};{};{};{};{};{};\\n'.format(threshold, percent ,n_parameters, acc[1][0], acc[1][1], acc[1][2], acc[1][3], acc[1][4]))\n",
    "            print ('acc = {}'.format(acc[1][0]))\n",
    "            print ('n_parameters = {}'.format(n_parameters))\n",
    "            print ('-----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_std(X_drop, y_drop, model):\n",
    "    d_relu_values = {}\n",
    "\n",
    "    for i in range(len(X_drop)):\n",
    "        if (i%1000 == 0): print ('processing img #{}'.format(i))\n",
    "        filename = X_drop[i]\n",
    "        exp_out = y_drop[i]\n",
    "\n",
    "        input_image = Image.open(filename)\n",
    "        try:\n",
    "            input_tensor = preprocess(input_image)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        input_tensor = preprocess(input_image)\n",
    "        input_batch = torch.unsqueeze(input_tensor, 0) # create a mini-batch as expected by the model\n",
    "\n",
    "        # move the input and model to GPU for speed if available\n",
    "        if torch.cuda.is_available():\n",
    "            input_batch = input_batch.to(device)\n",
    "            model.to(device)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            out_model = model.forward(input_batch)\n",
    "        #out_model = model.forward(input_batch)\n",
    "\n",
    "        out_softmax = torch.nn.functional.softmax(out_model[-1], dim=-1)\n",
    "        out_softmax = out_softmax.reshape(1000)\n",
    "\n",
    "        out_softmax = np.argmax(out_softmax.cpu().detach().numpy())\n",
    "        #print (len(out_model))\n",
    "        #input()\n",
    "        for j in range(1, len(out_model)-1):\n",
    "            if (j not in d_relu_values): d_relu_values[j] = []\n",
    "\n",
    "            out = out_model[j].cpu().detach().numpy()\n",
    "\n",
    "            out_previous_layer = out_model[j-1].cpu().detach().numpy()\n",
    "\n",
    "            for k in range(len(out[0])):\n",
    "                v = out[0][k]\n",
    "                d_relu_values[j].append(v)\n",
    "\n",
    "    for l in d_relu_values:\n",
    "        d_relu_values[l] = list(d_relu_values[l])\n",
    "\n",
    "    d_relu_mean = {}\n",
    "    d_relu_std  = {}\n",
    "\n",
    "    for l in d_relu_values:\n",
    "        d_relu_mean[l] = np.mean(d_relu_values[l])\n",
    "        d_relu_std[l]  = np.std(d_relu_values[l])\n",
    "\n",
    "    return d_relu_mean, d_relu_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing img #0\n",
      "processing img #1000\n",
      "d_relu_mean: {1: 0.5341921, 2: 0.25907692}\n",
      "d_relu_std: {1: 1.3999276, 2: 0.7812767}\n"
     ]
    }
   ],
   "source": [
    "d_relu_mean, d_relu_std = compute_mean_std(X_drop, y_drop, model)\n",
    "print ('d_relu_mean: {}'.format(d_relu_mean))\n",
    "print ('d_relu_std: {}'.format(d_relu_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing img #0 (3.5869888961315155e-06s)\n",
      "processing img #1000 (121.03217908900115s)\n",
      "passou..\n",
      "layer: 1. len = 4096\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-69e63ef99601>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprefix_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./results/exp_17_10_2021__/res_50_classes'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mis_by_both_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mcompute_ace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_drop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_drop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_by_both_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-28-1228e43d2e21>\u001b[0m in \u001b[0;36mcompute_ace\u001b[0;34m(X_drop, y_drop, is_by_both_class)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;31m#NA TENTATIVA DE COMPUTAR O ACE POR CLASSE!!!!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;31m#l_ace[label] = compute_ace_for_class(p_z, p_x_given_z, comb_z_x_index, p_y_given_x, label)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0ml_ace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_ace_for_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_z\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_x_given_z\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomb_z_x_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_y_given_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mfout_ace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix_filename\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'ace.txt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-7b1317f491d4>\u001b[0m in \u001b[0;36mcompute_ace_for_class\u001b[0;34m(p_z, p_x_given_z, comb_z_x_index, p_y_given_x, label)\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;31m#    if (p_y_given_x[layer][label][comb_x][1] == 0): continue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcomb_x\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mp_y_given_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#max 50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mp_y_given_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcomb_x\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m                 \u001b[0;31m#só considera o x que ativado\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomb_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 1"
     ]
    }
   ],
   "source": [
    "#d_relu_mean= {1: 0.5341921, 2: 0.25907692}\n",
    "#d_relu_std= {1: 1.3999276, 2: 0.7812767}\n",
    "\n",
    "prefix_filename = './results/exp_17_10_2021__/res_50_classes'\n",
    "is_by_both_class=False\n",
    "compute_ace(X_drop, y_drop, is_by_both_class)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
